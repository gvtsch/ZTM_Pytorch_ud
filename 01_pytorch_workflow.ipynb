{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore an example PyTorch end-to-end workflow.\n",
    "\n",
    "Ressources:\n",
    "* Ground truth notebook - https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
    "* Book version: https://www.learnpytorch.io/01_pytorch_workflow/\n",
    "* Ask a question: https://github.com/mrdbourke/pytorch-deep-learning/discussions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering = {1: \"data (prepare and load)\",\n",
    "                      2: \"build model\",\n",
    "                      3: \"Fiiting the model to data (training)\",\n",
    "                      4: \"making predictions and evaluate a model (inference)\",\n",
    "                      5: \"saving and loading a model\",\n",
    "                      6: \"putting it all together\"}\n",
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn # neural network module\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data (preparing and loading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be almost anything ... in machine learning\n",
    "\n",
    "* Excel spreadsheet\n",
    "* Images\n",
    "* Videos\n",
    "* Audio\n",
    "* DNA\n",
    "* Text\n",
    "* ... \n",
    " \n",
    " ML is a game of two parts:\n",
    " 1. Get data into numerical representation.\n",
    " 2. Build a model to learn patterns in that numerical representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01-machine-learning-a-game-of-two-parts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To showcaes this, let's create some *known* showcase data using linear regression formula.\n",
    "\n",
    "We'll use a linear regression formula to make a straight line with *known* **parameters**.\n",
    "\n",
    "\\begin{equation}\n",
    "Y_i = f(X_i, \\beta) + e_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create \n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10], len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and test sets\n",
    "(One of the most important concepts in machine learning in general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train/test split\n",
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might we better visualize our data?\n",
    "\n",
    "This is where the data explorer's motto comes in!\n",
    "\n",
    "\"Visualize, visualize, ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot of y above X\n",
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "    \n",
    "    \"\"\" Plots training data, test data and compares predictions. \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(train_data, train_labels, c='b', label='Training data')\n",
    "    plt.scatter(test_data, test_labels, c='g', label='Testing data')\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c='r', label='Predictions')\n",
    "    plt.legend()\n",
    "    plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot of training and test data\n",
    "plot_predictions(train_data=X_train, \n",
    "                 train_labels=y_train, \n",
    "                 test_data=X_test, \n",
    "                 test_labels=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first Pytorch model!\n",
    "\n",
    "Because we are going to be building classes throughout the course, I'd recommend getting familiar with OOP in Python, to do so you can use the following resource from Real Python...\n",
    "\n",
    "What the model does:\n",
    "* Start with random values (weight & bias)\n",
    "* Look at training data and adjust the random values to better represint (or get closer to) the ideal values (the weight & bias values we used to create the data)\n",
    "\n",
    "How does it do so?\n",
    "\n",
    "Through two main algorithms:\n",
    "1. Gradient descent\n",
    "2. Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model class\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This class represents a linear regression model in PyTorch. It inherits from the `nn.Module` class\n",
    "    and implements the necessary methods for defining the computation in the model.\n",
    "    \n",
    "    Attributes:\n",
    "        weights (nn.Parameter): The weight parameter of the linear regression model.\n",
    "        bias (nn.Parameter): The bias parameter of the linear regression model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Forward method to define the computation in the model. \"\"\"\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Subclass `nn.Module` contains all the building blocks for neural networks\n",
    "* Initialize `model.parameters` to be used in various computations (these could be different layers from `torch.nn`, single parameters, hard-coded values or functions)\n",
    "* `requires_grad=True` means PyTorch will track the gradients of this specific parameter for use with `torch.autograd` and gradient descent (for many `torch.nn` modules, `requires_grad=True` is set by default)\n",
    "* Any subclass of `nn.Module` needs to override `forward()` (this defines the forward computation of the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch model building essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torch.nn` - Contains all of the buildings for computational graphs (a neural network can be considered a computational graph)\n",
    "* `torch.nn.Parameter` - What parameters should our model try and learn, often a PyTorch layer from `torch.nn` will set these for us\n",
    "* `torch.nn.Module` - The baseclass for all neural network modules, if you subclass it, one should override `forward()`\n",
    "* `torch.optim` - This is where the optimizers in PyTorch live, they will help with gradient descent\n",
    "* `def forward()` - All `nn.Module` subclasses require you to override `forward()`, this method defines what happens in the forward computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the contents of our PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've created a model, let's see what's inside...\n",
    "\n",
    "So we can check our model parameters or what's inside our model using `.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the LinearRegressionModel\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check the model's parameters\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions using `torch.inference_mode()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check our model's predictive powern, let's see how well it predicts `y_test` based on `X_test`.\n",
    "\n",
    "When we pass data through our model, it's goingo to run through the `forward()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *know* parameters.  \n",
    "\n",
    "Or in other words from poor representation of the data to a better representation of the data.\n",
    "\n",
    "One way to measure how poor or how wrong our model predictions are, is to use a loss function.\n",
    "\n",
    "* Note: Loss function may also be called cost function or criterion in different areas. For our case, we're going to refer to it as a loss function.\n",
    "\n",
    "Things we need to train:\n",
    "\n",
    "* **Loss function**: A function to measuren how wrong the predictions are compared to the ideal output. The lower the better. \n",
    "* **Optimize.**: Takes into account the loss of the model and adjusts the model's parameters (e.g. weight & bias in our case) to improve the loss function.\n",
    "    * Inside the optimizer one'll often have to set two parameters:\n",
    "        * `params` - the model parameters one would like to optimize, for example `params=model_0.parameters()`\n",
    "        * `lr` - the learning rate is a hyperparameter that defines how big/small the optimizer changes the parameters with each step (a small `lr` results in small changes, a large `lr` results in large changes)\n",
    "\n",
    "And specifically for PyTorch, we need:\n",
    "* A training loop\n",
    "* A testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup an optimizer (SGD)\n",
    "optimizer = torch.optim.SGD(\n",
    "    model_0.parameters(), \n",
    "    lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Which loss function and opimizer should i use?  \n",
    "**A**: This will be problem specific. But with experience, one'll get an idea of what works and what does not with your particular problem set.\n",
    "\n",
    "For example, for a regression problem (like this one), a loss function of `nn.L1Loss` and an optimizer like `torch.optim.SGD()` will suffice.  \n",
    "But for a classification problem like classfying whether a photo is of a dog or a cat, one will likely want to use a loss function of `nn.BCELoss()` (binary cross entropy loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a training (and testing) loop in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things we need in a training loop:\n",
    "\n",
    "0. Loop through the data and do the following: \n",
    "1. Forward pass (this involves data moving throuwh our model's `forward()` functions) to make predictions on data - also called forward propagation\n",
    "2. Calculate the loss (compare forward pass predictions to ground truth labels)\n",
    "3. Optimizer zero grad\n",
    "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss (**backpropagation**)\n",
    "5. Optimizer step - Use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# An epoch is one loop through the entire dataset ... (this is a hyperparameter because we set it ourselves)\n",
    "epochs = 200\n",
    "\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "## Training the model\n",
    "# 0. Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    model_0.train() # Set the model to train mode: Sets all parameters that require gradients to require gradients\n",
    "\n",
    "    y_pred = model_0(X_train) # Make predictions\n",
    "    \n",
    "    loss = loss_fn(y_train, y_pred) # Calculate the loss\n",
    "\n",
    "    optimizer.zero_grad() # Zero the gradients\n",
    "\n",
    "    loss.backward() # Calculate gradients\n",
    "\n",
    "    optimizer.step() # Update the weights\n",
    "\n",
    "    # Testing / Evaulating the model\n",
    "    model_0.eval() # Turns off different settings, which are not needed for testing/evaluation\n",
    "    with torch.inference_mode(): # Turns off gradient tracking\n",
    "        test_preds = model_0(X_test)  \n",
    "\n",
    "        test_loss = loss_fn(y_test, test_preds)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)\n",
    "        \n",
    "        print(f\"Epoch: {epoch} --- Loss: {loss} --- Test loss: {test_loss}\") \n",
    "        print(f\"Model state_dict: {model_0.state_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss values over the epochs\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(epoch_count, np.array(torch.tensor(loss_values).cpu().numpy()), label='training loss')\n",
    "plt.plot(epoch_count, test_loss_values, label='test loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and test loss curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds_after_training = model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds_after_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a model in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main methods one should know about for saving and loading models in PyTorsch.\n",
    "\n",
    "1. `torch.save()` - allows you to save a PyTorch object in Python's .pkl-Format\n",
    "2. `torch.load()` - allows you to load a saved PyTorch object\n",
    "3. `torch.nn.Module.load_state_dict()` - allows to load a  model's saved state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a directory to save the model\n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "MODEL_SAVE_PATH\n",
    "\n",
    "# 3. Save model's state_dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(\n",
    "    obj=model_0.state_dict(), \n",
    "    f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we saved our model's `state_dict()` rather the entire model, we'll create a new instance of our model class and load the saved `state_dict()` into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load in a saved state_dict we have to instantiate a new instance of our model class\n",
    "loaded_model_0 = LinearRegressionModel()\n",
    "\n",
    "# Load the saved state_dict of model_0 (this will update the new instance with updated parameters)\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_0.state_dict(), model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moke some predictions with our loaded model\n",
    "loaded_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_model_0(X_test)\n",
    "\n",
    "loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare loaded model preds with original model preds\n",
    "y_preds_after_training == loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
